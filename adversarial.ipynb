{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1aNlTjIvDlM"
      },
      "source": [
        "### Generating human faces with Adversarial Networks\n",
        "<img src=\"https://www.strangerdimensions.com/wp-content/uploads/2013/11/reception-robot.jpg\" width=320>\n",
        "This time we'll train a neural net to generate plausible human faces in all their subtlty: appearance, expression, accessories, etc.\n",
        "\n",
        "Based on https://github.com/Lasagne/Recipes/pull/94 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M5JJlccvDlN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "plt.rcParams.update({'axes.titlesize': 'small'})\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "#The following line fetches you two datasets: images, usable for autoencoder training and attributes.\n",
        "from lfw_dataset import fetch_lfw_dataset\n",
        "data,attrs = fetch_lfw_dataset(dimx=36,dimy=36)\n",
        "\n",
        "#preprocess faces\n",
        "data = np.float32(data)/255.\n",
        "\n",
        "IMG_SHAPE = data.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1lWNvL4vDlO"
      },
      "outputs": [],
      "source": [
        "#print random image\n",
        "plt.imshow(data[np.random.randint(data.shape[0])], cmap=\"gray\", interpolation=\"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDCJQmT5vDlP"
      },
      "source": [
        "# Generative adversarial nets 101\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/model.png\" width=320px height=240px>\n",
        "\n",
        "Deep learning is simple, isn't it?\n",
        "* build some network that generates the face (small image)\n",
        "* make up a __measure__ of __how good that face is__\n",
        "* optimize with gradient descent\n",
        "\n",
        "\n",
        "The only problem is: how can we tell well-generated faces from bad?\n",
        "\n",
        "__If we can't tell good faces from bad, we delegate it to yet another neural network!__\n",
        "\n",
        "That makes the two of them:\n",
        "* __G__enerator - takes random noize for inspiration and tries to generate a face sample.\n",
        "  * Let's call him __G__(z), where z is a gaussian noize.\n",
        "* __D__iscriminator - takes a face sample and tries to tell if it's great or fake.\n",
        "  * Predicts the probability of input image being a __real face__\n",
        "  * Let's call him __D__(x), x being an image.\n",
        "  * __D(x)__ is a predition for real image and __D(G(z))__ is prediction for the face made by generator.\n",
        "\n",
        "Before we dive into training them, let's construct the two networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDAL_USXvDlP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers as L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5AliRd4vDlP"
      },
      "outputs": [],
      "source": [
        "CODE_SIZE = 256\n",
        "\n",
        "generator = Sequential()\n",
        "generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
        "generator.add(L.Dense(10*8*8, activation='elu'))\n",
        "\n",
        "generator.add(L.Reshape((8,8,10)))\n",
        "generator.add(L.Conv2DTranspose(64,kernel_size=(5,5),activation='elu'))\n",
        "generator.add(L.Conv2DTranspose(64,kernel_size=(5,5),activation='elu'))\n",
        "generator.add(L.UpSampling2D(size=(2,2)))\n",
        "generator.add(L.Conv2DTranspose(32,kernel_size=3,activation='elu'))\n",
        "generator.add(L.Conv2DTranspose(32,kernel_size=3,activation='elu'))\n",
        "generator.add(L.Conv2DTranspose(32,kernel_size=3,activation='elu'))\n",
        "\n",
        "<figure out the last layer setup>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1wbKSgnvDlP"
      },
      "outputs": [],
      "source": [
        "assert generator.output_shape[1:] == IMG_SHAPE, \"generator must output an image of shape %s, but instead it produces %s\"%(IMG_SHAPE,generator.output_shape[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sABkMVfHvDlQ"
      },
      "source": [
        "### Discriminator\n",
        "Discriminator is your usual convolutional network with interlooping convolution and pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahbLHSxKvDlQ"
      },
      "outputs": [],
      "source": [
        "discriminator = Sequential()\n",
        "\n",
        "discriminator.add(L.InputLayer(IMG_SHAPE))\n",
        "\n",
        "<build discriminator body>\n",
        "\n",
        "discriminator.add(L.Flatten())\n",
        "discriminator.add(L.Dense(256,activation='tanh'))\n",
        "discriminator.add(L.Dense(2,activation=tf.nn.log_softmax))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a07Xd-SQvDlQ"
      },
      "source": [
        "# Training\n",
        "\n",
        "We train the two networks concurrently:\n",
        "* Train __discriminator__ to better distinguish real data from __current__ generator\n",
        "* Train __generator__ to make discriminator think generator is real\n",
        "\n",
        "![img](gan.png)\n",
        "\n",
        "Training is done iteratively until discriminator is no longer able to find the difference (or until you run out of patience).\n",
        "\n",
        "\n",
        "### Tricks:\n",
        "* You can find useful tricks here https://github.com/soumith/ganhacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDNPnaOpvDlQ"
      },
      "source": [
        "### Auxilary functions\n",
        "Here we define a few helper functions that draw current data distributions and sample training batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeSo4pMAvDlQ"
      },
      "outputs": [],
      "source": [
        "def sample_noise_batch(bsize):\n",
        "    return np.random.normal(size=(bsize, CODE_SIZE)).astype('float32')\n",
        "\n",
        "def sample_data_batch(bsize):\n",
        "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
        "    return data[idxs]\n",
        "\n",
        "def sample_images(nrow,ncol, sharp=False):\n",
        "    images = generator.predict(sample_noise_batch(bsize=nrow*ncol))\n",
        "    if np.var(images)!=0:\n",
        "        images = images.clip(np.min(data),np.max(data))\n",
        "    for i in range(nrow*ncol):\n",
        "        plt.subplot(nrow,ncol,i+1)\n",
        "        if sharp:\n",
        "            plt.imshow(images[i].reshape(IMG_SHAPE),cmap=\"gray\", interpolation=\"none\")\n",
        "        else:\n",
        "            plt.imshow(images[i].reshape(IMG_SHAPE),cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "def sample_probas(bsize):\n",
        "    plt.title('Generated vs real data')\n",
        "    plt.hist(np.exp(discriminator.predict(sample_data_batch(bsize)))[:,1],\n",
        "             label='D(x)', alpha=0.5,range=[0,1])\n",
        "    plt.hist(np.exp(discriminator.predict(generator.predict(sample_noise_batch(bsize))))[:,1],\n",
        "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP30W_WEvDlR"
      },
      "source": [
        "### Training\n",
        "Main loop.\n",
        "We just train generator and discriminator in a loop and draw results once every N iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZyLOfwfvDlR"
      },
      "outputs": [],
      "source": [
        "disc_optimizer = tf.optimizers.\n",
        "gen_optimizer = tf.optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIKH3dXNvDlR"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "from tqdm import tnrange\n",
        "\n",
        "for epoch in tnrange(50000):\n",
        "    real_data = sample_data_batch(100)\n",
        "    noise = sample_noise_batch(100)\n",
        "\n",
        "\n",
        "    ########################\n",
        "    #discriminator training#\n",
        "    ########################\n",
        "    for i in range(5):\n",
        "        logp_real = discriminator(real_data)\n",
        "\n",
        "        generated_data = <gen(noise)>\n",
        "\n",
        "        logp_gen = <log P(real | gen(noise))\n",
        "\n",
        "        d_loss = -tf.reduce_mean(logp_real[:,1] + logp_gen[:,0])\n",
        "\n",
        "        #regularize\n",
        "        d_loss += tf.reduce_mean(discriminator.layers[-1].kernel**2)\n",
        "\n",
        "        #optimize\n",
        "        disc_optimiser.minimize(d_loss, var_list=discriminator.trainable_weights)\n",
        "\n",
        "    ########################\n",
        "    ###generator training###\n",
        "    ########################\n",
        "    g_loss = <generator loss>\n",
        "\n",
        "    #optimize\n",
        "    gen_optimizer.minimize(g_loss, var_list=generator.trainable_variables)\n",
        "\n",
        "    if epoch %100==0:\n",
        "        display.clear_output(wait=True)\n",
        "        sample_images(2,3,True)\n",
        "        sample_probas(1000)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE8DYfHwvDlR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[16,24])\n",
        "sample_images(16,8)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}